✅ 模型加载完成 cuda
Traceback (most recent call last):
  File "/home/algo/hrz/db_construct/reranker_ft.py", line 66, in <module>
    model.fit(
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/sentence_transformers/cross_encoder/fit_mixin.py", line 303, in fit
    args = CrossEncoderTrainingArguments(
  File "<string>", line 131, in __init__
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/sentence_transformers/training_args.py", line 190, in __post_init__
    super().__post_init__()
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 1641, in __post_init__
    and (self.device.type == "cpu" and not is_torch_greater_or_equal_than_2_3)
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 2149, in device
    return self._setup_devices
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/utils/generic.py", line 59, in __get__
    cached = self.fget(obj)
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 2081, in _setup_devices
    self.distributed_state = PartialState(
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/accelerate/state.py", line 304, in __init__
    raise NotImplementedError(
NotImplementedError: Using RTX 4000 series doesn't support faster communication broadband via P2P or IB. Please set `NCCL_P2P_DISABLE="1"` and `NCCL_IB_DISABLE="1" or use `accelerate launch` which will do this automatically.
Traceback (most recent call last):
  File "/home/algo/hrz/db_construct/reranker_ft.py", line 66, in <module>
    model.fit(
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/sentence_transformers/cross_encoder/fit_mixin.py", line 303, in fit
    args = CrossEncoderTrainingArguments(
  File "<string>", line 131, in __init__
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/sentence_transformers/training_args.py", line 190, in __post_init__
    super().__post_init__()
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 1641, in __post_init__
    and (self.device.type == "cpu" and not is_torch_greater_or_equal_than_2_3)
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 2149, in device
    return self._setup_devices
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/utils/generic.py", line 59, in __get__
    cached = self.fget(obj)
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/transformers/training_args.py", line 2081, in _setup_devices
    self.distributed_state = PartialState(
  File "/home/algo/miniconda3/envs/htmlRAG/lib/python3.9/site-packages/accelerate/state.py", line 304, in __init__
    raise NotImplementedError(
NotImplementedError: Using RTX 4000 series doesn't support faster communication broadband via P2P or IB. Please set `NCCL_P2P_DISABLE="1"` and `NCCL_IB_DISABLE="1" or use `accelerate launch` which will do this automatically.
