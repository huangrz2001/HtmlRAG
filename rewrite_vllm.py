import json
import argparse
import requests
import time
import asyncio
import aiohttp
import json
import time


def build_prompt(dialogue, final_query):
    prompt = (
        "ä½ æ˜¯ä¸€ä¸ªç”µå•†å¹³å°æ™ºèƒ½å®¢æœçš„å¯¹è¯æ¸…æ™°åŒ–åŠ©æ‰‹ã€‚\n"
        "ç”¨æˆ·æå‡ºçš„é—®é¢˜å¯èƒ½å­˜åœ¨å¤æ‚æŒ‡ä»£ã€ä¸Šä¸‹æ–‡ä¾èµ–æˆ–è¡¨è¾¾æ¨¡ç³Šç­‰é—®é¢˜ã€‚\n"
        "ä½ éœ€è¦æ ¹æ®å¤šè½®å†å²å¯¹è¯ï¼Œä¸°å¯Œæ¶¦è‰²ç”¨æˆ·çš„å½“å‰é—®é¢˜ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæ¸…æ™°ã€å®Œæ•´çš„ç‹¬ç«‹é—®é¢˜ã€‚\n\n"
        "ä¸‹é¢æ˜¯è¦æ±‚ï¼š\n"
        "- å‡†ç¡®è§£æç”¨æˆ·çœŸå®æ„å›¾ï¼Œä½¿å¾—è¿™ä¸ªç‹¬ç«‹é—®é¢˜å°½é‡å®Œæ•´ï¼Œå°½å¯èƒ½åŒ…å«æ‰€æœ‰ä¿¡æ¯ï¼›\n"
        "- é—®é¢˜è¶Šä¸°å¯Œè¶Šå¥½ï¼Œç‰¹åˆ«æ˜¯è¦æ•æ‰åˆ°å…³é”®çš„æŒ‡ä»£ï¼Œåœºæ™¯ï¼Œç‰¹åˆ«é’ˆå¯¹çš„é—®é¢˜å’Œä¾‹å­ç­‰ç­‰ï¼›\n"
        "- ä¸å¯ä»¥æé€ ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼›\n"
        "- ä¸æ·»åŠ è§£é‡Šã€æ³¨é‡Šã€å¼•å¯¼è¯­ç­‰ï¼Œåªè¾“å‡ºæ¶¦è‰²åçš„é—®é¢˜å¥ã€‚\n\n"
        "ä¸‹é¢æ˜¯å†å²å¯¹è¯ï¼š\n"
    )
    for turn in dialogue:
        role = "ç”¨æˆ·" if turn["speaker"] == "user" else "ç³»ç»Ÿ"
        content = turn["text"].replace("\n", " ").strip()
        prompt += f"{role}ï¼š{content}\n"

    prompt += f"ç”¨æˆ·å½“å‰é—®é¢˜æ˜¯ï¼š{final_query.strip()}\nè¯·ä½ éµå¾ªè¦æ±‚æ¶¦è‰²ä¸ºä¸€ä¸ªæ¸…æ™°ã€å®Œæ•´çš„ç‹¬ç«‹é—®é¢˜ï¼š"
    return prompt


def rewrite_query_vllm_requests(dialogue, final_query, api_url="http://localhost:8000/v1/chat/completions", max_tokens=128):
    prompt = build_prompt(dialogue, final_query)
    payload = {
        "model": "glm",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": max_tokens,
        "temperature": 0.4,
        "top_p": 0.8,
    }

    try:
        start = time.time()
        response = requests.post(api_url, headers={"Content-Type": "application/json"}, json=payload, timeout=60)
        duration = time.time() - start
        response.raise_for_status()
        result = response.json()["choices"][0]["message"]["content"].strip()
        return result or final_query, duration
    except Exception as e:
        print(f"âš ï¸ vLLM è¯·æ±‚å¤±è´¥: {e}")
        return final_query, -1


async def query_once(session, url, payload):
    async with session.post(url, json=payload) as resp:
        data = await resp.json()
        return data["choices"][0]["message"]["content"].strip()

async def main(input_file):
    with open(input_file, "r", encoding="utf-8") as f:
        dataset = [json.loads(line) for line in f]

    url = "http://localhost:8000/v1/chat/completions"
    headers = {"Content-Type": "application/json"}

    prompts = []
    for item in dataset:
        prompt = build_prompt(item["dialogue"], item["final_query"])
        prompts.append({
            "model": "glm",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 128,
            "temperature": 0.4,
            "top_p": 0.8
        })

    start_time = time.time()
    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = [query_once(session, url, p) for p in prompts]
        responses = await asyncio.gather(*tasks)

    # print(responses)
    end_time = time.time()
    print(f"âœ… å¹¶å‘å®Œæˆ {len(responses)} æ¡è¯·æ±‚ï¼Œè€—æ—¶: {end_time - start_time:.2f}s")




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_file", type=str, default="rewriting_test_set.jsonl", help="è¾“å…¥çš„ JSONL æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # ä½¿ç”¨å¼‚æ­¥æ–¹å¼æ‰¹é‡æŸ¥è¯¢
    asyncio.run(main(args.input_file))

    # æµ‹è¯•å•æ¡æŸ¥è¯¢
    # dialogue = [{"speaker": "user", "text": "å¦‚ä½•è¿è¥å·¨é‡åƒå·å¹³å°ï¼Ÿ"}]
    # final_query = "å¦‚ä½•è¿è¥å·¨é‡åƒå·å¹³å°ï¼Ÿ"
    # result, duration = rewrite_query_vllm_requests(dialogue, final_query)
    # print(f"ğŸ”¹ åŸé—®é¢˜: {final_query}")
    # print(f"âœ… é‡å†™å: {result} (è€—æ—¶: {duration:.2f} ç§’)")