import os
import json
import base64
import requests
import re
import torch
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List

from langchain_huggingface import HuggingFaceEmbeddings
from utils.html_utils import clean_html, build_block_tree
from utils.text_process_utils import generate_block_documents, generate_block_documents_async
from utils.db_utils import (
    insert_block_to_es, insert_block_to_milvus,
    delete_blocks_from_es, delete_blocks_from_milvus
)
from utils.llm_api import rewrite_query_vllm, rewrite_query_vllm_async
from utils.config import CONFIG, logger
import asyncio
import aiofiles
from functools import partial
import time


# ======================== åµŒå…¥æ¨¡å‹åŠ è½½ ========================
DEVICE = CONFIG.get("device", f"cuda:0" if torch.cuda.is_available() else "cpu")

embedder = HuggingFaceEmbeddings(
    model_name=CONFIG["embed_model"],
    model_kwargs={"device": DEVICE}
)

# ======================== å…¬å…±å‡½æ•° ========================
def parse_time_tag(html: str):
    pattern = r"^\s*<time[^>]*?>(.*?)</time>"
    match = re.match(pattern, html, flags=re.IGNORECASE | re.DOTALL)
    return (match.group(1).strip(), html[match.end():].lstrip()) if match else ("", html)

# ========== è¾…åŠ©å‡½æ•° ==========
def get_local_html_path(page_url: str) -> str:
    """
    åœ¨å½“å‰é¡¹ç›®ç›®å½•ä¸‹æ„é€ ç¼“å­˜æ–‡ä»¶çš„è·¯å¾„ï¼Œç›®å½•ä¸º ./archive/
    """
    return os.path.join(os.path.dirname(__file__), "archive", page_url)

async def async_remove(path: str):
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(None, partial(os.remove, path))


def download_html(resource_id: int, blackhole_url: str, save_path: str) -> str:
    """
    ä»é»‘æ´æœåŠ¡å™¨ä¸‹è½½ Base64 æ–‡ä»¶å†…å®¹å¹¶ä¿å­˜åˆ°æœ¬åœ°æŒ‡å®šè·¯å¾„ï¼Œå¹¶è®°å½•è€—æ—¶
    """
    url = f"http://{blackhole_url}/resource/withoutLogin/downloadWithBase64"
    start_time = time.perf_counter()

    try:
        resp = requests.post(url, json={"resourceId": resource_id}, timeout=10)
        resp.raise_for_status()
        resp_data = resp.json()

        if resp_data.get("code") != 200000 or "data" not in resp_data:
            raise ValueError(f"è¯·æ±‚å¤±è´¥æˆ–å“åº”æ— æ•ˆ: {resp_data}")

        content_base64 = resp_data["data"].get("content")
        if not content_base64:
            raise ValueError(f"å“åº”ä¸­ç¼ºå°‘ content å­—æ®µ: {resp_data}")

        content_bytes = base64.b64decode(content_base64)
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        with open(save_path, "wb") as f:
            f.write(content_bytes)

        elapsed_ms = (time.perf_counter() - start_time) * 1000
        logger.info(f"âœ… é»‘æ´ä¸‹è½½æˆåŠŸ: {resource_id} -> {save_path}ï¼Œè€—æ—¶ {elapsed_ms:.2f} ms")
        return save_path

    except Exception as e:
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        logger.error(f"âŒ é»‘æ´ä¸‹è½½å¤±è´¥: {resource_id} -> {save_path}ï¼Œè€—æ—¶ {elapsed_ms:.2f} msï¼Œé”™è¯¯: {e}")
        return None



# ========== æ’å…¥å¼‚æ­¥æ¥å£ ==========
async def insert_html_api_async(document_index: int, page_url: str, resource_id: int, blackhole_url: str):
    logger.info(f"ğŸ“¥ æ’å…¥è¯·æ±‚: document_index={document_index}, page_url={page_url}, resource_id={resource_id}")

    html_path = get_local_html_path(page_url)
    if not os.path.exists(html_path):
        logger.info(f"{html_path} æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæœ¬åœ°è·¯å¾„: %sï¼Œå°è¯•ä»é»‘æ´ä¸‹è½½...", html_path)
        downloaded_path = download_html(resource_id, blackhole_url, html_path)
        if not downloaded_path or not os.path.exists(downloaded_path):
            logger.error("âŒ HTML æ–‡ä»¶ä¸‹è½½å¤±è´¥: %s", html_path)
            return {"result": "fail", "error": "HTML æ–‡ä»¶ä¸‹è½½å¤±è´¥"}

    try:
        async with aiofiles.open(html_path, "r", encoding="utf-8") as f:
            html_raw = await f.read()
        logger.info("%s HTML æ–‡ä»¶è¯»å–å®Œæˆ", page_url)

        time_value, cleaned_part = parse_time_tag(html_raw)
        cleaned_html = clean_html(cleaned_part)
        logger.info("%s HTML æ¸…æ´—ä¸æ—¶é—´æ ‡ç­¾æå–å®Œæˆ", page_url)

        block_tree, _ = build_block_tree(
            cleaned_html,
            max_node_words=CONFIG["max_node_words_embed"],
            min_node_words=CONFIG["min_node_words_embed"],
            zh_char=(CONFIG["lang"] == "zh")
        )
        logger.info("%s Block Tree æ„å»ºå®Œæˆ", page_url)

        doc_meta = await generate_block_documents_async(
            block_tree=block_tree,
            max_node_words=CONFIG["max_node_words_embed"],
            page_url=page_url,
            time_value=time_value,
            use_vllm=True,
            batch_size=CONFIG.get("vllm_batch_size", 32)
        )
        logger.info("%s æ–‡æ¡£å—ç”Ÿæˆå®Œæˆï¼Œchunk æ•°: %d", page_url, len(doc_meta))
        if len(doc_meta) == 0:
            logger.warning("%s ç”Ÿæˆçš„æ–‡æ¡£å—ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ HTML å†…å®¹", page_url)
            return {"result": "fail", "error": "åŸæ–‡æ¡£ä¸ºç©ºï¼Œæ— æ³•æ’å…¥"}

        for i, doc in enumerate(doc_meta):
            doc["document_index"] = document_index
            doc["chunk_idx"] = i
        logger.info("%s å¼€å§‹æ’å…¥ Milvus...", page_url)
        milvus_cnt = insert_block_to_milvus(doc_meta, embedder, CONFIG["index_name"])
        logger.info("%s å¼€å§‹æ’å…¥ ES...", page_url)
        es_cnt = insert_block_to_es(doc_meta, CONFIG["index_name"])
        logger.info("%s å‘é‡æ’å…¥å®Œæˆ: Milvus=%d, ES=%d", page_url, milvus_cnt, es_cnt)

        return {
            "result": "ok",
            "document_index": document_index,
            "inserted_chunks_milvus": milvus_cnt,
            "inserted_chunks_es": es_cnt
        }

    except Exception as e:
        logger.exception("%s æ’å…¥å¤±è´¥:", page_url)
        return {"result": "fail", "error": f"æ’å…¥å¤±è´¥: {str(e)}"}

# ======================== åˆ é™¤æ¥å£å®ç° ========================
async def delete_html_api_async(document_index: int, page_url: str):
    logger.info(f"ğŸ“¤ åˆ é™¤è¯·æ±‚: document_index={document_index}, page_url={page_url}")
    try:
        milvus_cnt = delete_blocks_from_milvus(CONFIG["index_name"], document_index)
        es_cnt = delete_blocks_from_es(CONFIG["index_name"], document_index)
        logger.info(f"{page_url} å‘é‡åˆ é™¤å®Œæˆ: Milvus=%d, ES=%d", milvus_cnt, es_cnt)

        local_path = get_local_html_path(page_url)
        if os.path.exists(local_path):
            logger.info(f"{page_url} æ£€æµ‹åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œå‡†å¤‡åˆ é™¤: {local_path}")
            try:
                await async_remove(local_path)
                logger.info(f"{page_url} æœ¬åœ°æ–‡ä»¶åˆ é™¤æˆåŠŸ: {local_path}")
            except Exception as e:
                logger.warning(f"{page_url} æœ¬åœ°æ–‡ä»¶å¼‚æ­¥åˆ é™¤å¤±è´¥: {e}")

        return {
            "result": "ok",
            "document_index": document_index,
            "deleted_chunks_milvus": milvus_cnt,
            "deleted_chunks_es": es_cnt
        }

    except Exception as e:
        logger.exception("âŒ åˆ é™¤å¤±è´¥:")
        return {"result": "fail", "error": f"åˆ é™¤å¤±è´¥: {str(e)}"}


# ======================== FastAPI å®šä¹‰ ========================
app = FastAPI(title="RAG æ–‡æ¡£æ¥å£", description="æ”¯æŒæ–‡æ¡£æ’å…¥ã€åˆ é™¤ã€query é‡å†™", root_path="/document")

class InsertRequest(BaseModel):
    document_index: int
    resource_id: int  # longç»“æ„ï¼Œæ–‡æ¡£èµ„æºid
    page_url: str

@app.post("/add", summary="æ–°å¢æ–‡æ¡£")
async def add_doc(req: InsertRequest):
    print(f"ğŸ“¥ æ’å…¥è¯·æ±‚: {req.document_index}, {req.page_url}")
    # 4008893141271707648
    result = await insert_html_api_async(req.document_index, req.page_url, req.resource_id, CONFIG.get("blackhole_url", "172.16.4.51:8082"))
    return JSONResponse(content=result)


class DeleteRequest(BaseModel):
    document_index: int
    page_url: str

@app.post("/delete", summary="åˆ é™¤æ–‡æ¡£")
async def delete_doc_async(req: DeleteRequest):
    result = await delete_html_api_async(req.document_index, req.page_url)
    return JSONResponse(content=result)

class DialogueTurn(BaseModel):
    speaker: str
    text: str

class RewriteRequest(BaseModel):
    dialogue: List[DialogueTurn]
    final_query: str

@app.post("/query_rewrite", summary="é‡å†™ Query")
async def rewrite_query(req: RewriteRequest):
    logger.info(f"é‡å†™è¯·æ±‚: åŸå§‹query={req.final_query}")
    try:
        dialogue = [{"speaker": d.speaker, "text": d.text} for d in req.dialogue]
        rewritten = await rewrite_query_vllm_async(dialogue, req.final_query)
        logger.info(f"{req.final_query} é‡å†™å®Œæˆ: {rewritten}")
        return {"status": "ok", "rewritten_query": rewritten}
    except Exception as e:
        logger.exception("{req.final_query} é‡å†™å¤±è´¥:")
        return {"status": "fail", "error": f"é‡å†™å¤±è´¥: {str(e)}"}


@app.get("/ping", summary="å¥åº·æ£€æŸ¥")
def ping():
    return {"status": "ok"}
